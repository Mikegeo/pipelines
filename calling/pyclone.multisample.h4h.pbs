#!/bin/bash
#PBS -l nodes=1:ppn=12,walltime=24:00:00,vmem=60g,mem=220g
#PBS -N variantCalls
#PBS -q himem
#PBS -V
#PBS -j oe
#PBS -m abe
#PBS -M slei.bass@gmail.com

:'
	This batch script accomplishes 6 separate tasks
	- task 1: index merged bam files
	- task 2: call copy number variants single samples at a time
	- task 3: call, categorize, filter clean point mutations
	- task 4: annotate mutations
	- task 5: data mining (VCF formatting, thresholding, feature wrangling)
	- task 6: clonal evolution from same individual dual exome samples
'

set -eux

module load java/8 samtools/1.9 bedtools/2.27.1
module load HTSeq/0.7.2 bwa/0.7.15 bedops/2.4.14 picard/2.10.9 
module load bamtools/2.4.2 tabix/0.2.6 varscan/2.4.2 
module load snpEff/4.3
module load R/3.5.0 python/2.7 
#module load python3/3.6.5 CNVkit/0.9.3 gatk/4.0.5.1 

## use the below exec when loading R
## java -jar $gatk_dir/gatk-package-4.0.5.1-local.jar HaplotypeCaller


## H4H directories
## Misc tools parameters
scratch=/cluster/projects/kridelgroup
_storage=$scratch/relapse/mutations
home=/cluster/home/sbassim
user_databases=$scratch/databases
admin_databases=/cluster/tools/data/genomes/human/hg19/variantcallingdata
pbs=$(echo $PBS_JOBID | cut -f1 -d '.')
time=$home/time
jobid=$pbs.exome_calling.multitool.annotated_pyclone
start=$(date); echo "Job started at: $start" > $time/$jobid.time

# __CHANGE__
pipeline=varscan
cnvs=cnmops
_protocol=removeFunctionV3
normal_cnv=2
minor_cnv=0
total_cnv=2
_priors=major_copy_number
_read_depth=50
_allel_pval=10e-25
_allel_freq=1

# __DONT CHANGE__
compression=0
threads=32
mapq=39
snpeff_genome=GRCh37.75
_data=$_storage/raw
workdir=$_storage/pyclone_analysis/$pbs
snpeff_config=$home/snpEff/snpEff.config
agilent=$_storage/targets/padded.clean.bed
ucsc=$_storage/targets/exons.ucsc.clean.bed
_pyclone_config=$_storage/pyclone_configs
## idx created from ClinVar annotating current samples
_variant_function=$_storage/variant_function.idx
_EXAC=$user_databases/gnomad.rs_position.idx
genome_reference=$user_databases/GRCh37-lite.fa


mkdir -p $workdir/yaml/$_priors
cp $_storage/pyclone_analysis/497746/variants/output.3_bash*vcf $workdir
cd $workdir

_listingFiles=$(find $_data -name "*bam")
for _idx in $_listingFiles; do

    sample_label=$(basename $_idx | cut -f1 -d'_')
    _DIR=$(dirname $_idx)



    output[3]=output.3_bash.snpeff_annot.$snpeff_genome.clinvar.dbsnp.$sample_label
    output[6]=output.6_bash.snpeff_annot.$_protocol.noFilter_clean.$sample_label
    output[7]=output.7_bash.snpeff_annot.$_protocol.reduced.clean_pyclone.$sample_label
    ## create personalized input for pyclone from annotated VCF
    ## get annotated (rs*) mutations (MU)
    ## clean based on annotated MU (dbsnp)
    ## clean double annotated MU (rs;rs)
    ## clean based on ADP (avg depth coverage phred >= 15)
    ## clean based on allele frequency
    ## clean based on allele p-value
    ## format table to include depth -i to reference and ii- to variant
    ## clean rows with false MU index

    if [ $_protocol == "removeFunctionV3" ]; then
	
	## output formatting based on clinvar and dbSnp annotation
	## this will keep gene handles
	## this will discard variants based on their functions (stop ..)
	## uses variant depth, allele freq, and pvalues
	## this will discard variants also found in exAC
	grep -v "^#" ${output[3]}.vcf \
	    | grep -v "rs" \
	    | sed -e 's/;WT=.*ANN=.|/\t/g' -e 's/|ENS.*:ADR//g' \
	    | cut -f1-2,4-5,8-10 \
	    | sed -e 's/ADP=//g' -e 's/|/\t/g' -e 's/:/\t/g' -e 's/%//g' \
	    | grep -vFwf <(cat $_EXAC) \
	    | tee ${output[6]}.txt \
	    | grep -vFwf <(cat $_variant_function) - \
	    | awk -va=$_allel_freq '{if($15 > a) print $0}' \
	    | awk -vd=$_read_depth '{if($5 >= d) print $0}' \
	    | awk -vp=$_allel_pval '{if($16 <= p) print $0}' \
	    | awk -F"\t" '{print$8"_"$1":"$2,$13,$14}' \
	    | sed -e 's/ /\t/g' -e "s/$/\t$normal_cnv\t$minor_cnv\t$total_cnv/g" \
	    | grep -v "^\." \
	    | grep -wv "FREQ" - \
		   > ${output[7]}.tsv

    else


	echo "Must specify whether to remove or keep annotated known SNVs!"
	exit 0

    fi
    

    sed -i "1i$(echo -e "mutation_id\tref_counts\tvar_counts\tnormal_cn\tminor_cn\tmajor_cn")" ${output[7]}.tsv


    ## summary reporting
    ## descriptive statistics
    ## distribution of variant by function
    output[8]=output.8_bash.summary.snv_functions.txt
    grep -v "^#" ${output[6]}.txt \
	| cut -f6 \
	| sort - \
	| uniq -c \
	| awk '{print $2,"\t",$1}' \
	| sed "s/$/\t$sample_label/g" \
	      >> ${output[8]}

    ## pvalues and variant frequencies (VAF) by all SNV position
    output[9]=output.9_bash.summary.snv.preFilter_distributions.txt
    grep -v "^#" ${output[6]}.txt \
	| cut -f1-2,15-16 \
	| sed "s/$/\t$sample_label/g" \
	      >> ${output[9]}


    ## pvalues and variant allele frequencies (VAF) by SNV position
    ## after discarding based on filters
    output[10]=output.10_bash.summary.snv.postFilter_VAFpval.txt
    grep -v "^#" ${output[6]}.txt \
	| grep -vFwf <(cat $_variant_function) - \
	| awk -va=$_allel_freq '{if($15 > a) print $0}' \
	| awk -vd=$_read_depth '{if($5 >= d) print $0}' \
	| awk -vp=$_allel_pval '{if($16 <= p) print $0}' \
	| awk -F"\t" '{print$8"_"$1":"$2,$5,$13,$14,$15,$16}' \
	| sed "s/$/\t$sample_label/g" \
	      >> ${output[10]}



done

## add headers for summary reports
sed -i "1i $(echo -e "function\tcount\tsample")" ${output[8]}
sed -i "1i $(echo -e "function\tcount\tsample")" ${output[9]}
sed -i "1i $(echo -e "snv\tDP\trefCounts\tvarCounts\tvaf\tpval\tsample")" ${output[10]}



##############################################
# Clonal evolution by pair samples (pyClone) #
##############################################
## preprocess VCF for assessement of clonal evolution
## main tool: pyclone
cd $workdir

## create config files, manually
## only samples from same individual are compared together
_yaml=$(find $_pyclone_config -name "*individual*yaml")

## change the directory of each config file
## for each analysis using same samples but different iteration
for _pyCfg in $_yaml; do
    new_name=$(basename $_pyCfg)

    cat $_pyCfg \
	| sed '2d' \
	      > $workdir/$new_name
    sed -i "1i$(echo "working_dir: $workdir")" $workdir/$new_name
        
done


## run python 2.7
## load pyclone 0.13.1 that I deployed
## do not load h4h pyclone (not correctly installed)
source activate pyclone

_listingFiles=$(find $_data -name "*bam")
for _idx in $_listingFiles; do

    sample_label=$(basename $_idx | cut -f1 -d'_')

    output[7]=output.7_bash.snpeff_annot.$_protocol.reduced.clean_pyclone.$sample_label
    ## build mutation file
    PyClone build_mutations_file \
	    --in_file ${output[7]}.tsv \
	    --out_file $workdir/yaml/total_copy_number/$sample_label.yaml \
	    --prior $_priors

done


## run final clonal evolution analysis
## MCMC 10,000 iterations
_configFiles=$(find $workdir -name "config*yaml")
for _cfg in $_configFiles; do

    _ix=$(basename $_cfg | sed -e 's/config.//g' -e 's/.yaml//g')
    
    ## build configuration file (manually)
    PyClone run_analysis --config_file $_cfg

    ## summary table
    PyClone build_table --config_file $_cfg \
	    --out_file pyclone.$_ix.exome.summary_table.txt \
	    --table_type loci

    ## plot
    PyClone plot_loci --config_file $_cfg \
	    --plot_file pyclone.$_ix.parallel.png \
	    --plot_type parallel_coordinates
    PyClone plot_loci --config_file $_cfg \
	    --plot_file pyclone.$_ix.similarity_matrix.png \
	    --plot_type similarity_matrix
    PyClone plot_loci --config_file $_cfg \
	    --plot_file pyclone.$_ix.density.png \
	    --plot_type density
done

source deactivate


## repo organization
sleep 300
cd $workdir
mkdir configs figures pyclone_input reports variants
mv *tsv pyclone_input
mv *vcf variants
mv conf*yaml configs
mv *txt reports
mv *pdf *png *html figures




end=$(date); echo "Job ended at: $end" >> $time/$jobid.time

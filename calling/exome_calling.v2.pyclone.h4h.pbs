#!/bin/bash
#PBS -l nodes=1:ppn=32,walltime=120:00:00,vmem=60g,mem=220g
#PBS -N variantCalls
#PBS -q himem
#PBS -V
#PBS -j oe
#PBS -m abe
#PBS -M slei.bass@gmail.com

set -eux

module load java/8 samtools/1.9 bedtools/2.27.1
module load HTSeq/0.7.2 bwa/0.7.15 bedops/2.4.14 picard/2.10.9 
module load bamtools/2.4.2 tabix/0.2.6 varscan/2.4.2 
module load snpEff/4.3
module load R/3.5.0 python/2.7 
#module load python3/3.6.5 CNVkit/0.9.3 gatk/4.0.5.1 

## use the below exec when loading R
## java -jar $gatk_dir/gatk-package-4.0.5.1-local.jar HaplotypeCaller


## H4H directories
## Misc tools parameters
scratch=/cluster/projects/kridelgroup
_storage=$scratch/relapse/mutations
home=/cluster/home/sbassim
user_databases=$scratch/databases
genome_reference=$scratch/databases/GRCh37-lite.fa
admin_databases=/cluster/tools/data/genomes/human/hg19/variantcallingdata
pbs=$(echo $PBS_JOBID | cut -f1 -d '.')
time=$home/time
jobid=$pbs.exome_calling.multitool.annotated_pyclone
start=$(date); echo "Job started at: $start" > $time/$jobid.time

# __CHANGE__
sampling=FALSE
pipeline=varscan
cnvs=cnmops

# __DONT CHANGE__
compression=0
threads=32
mapq=39
minor_cnv=0
normal_cnv=2
snpeff_genome=GRCh37.75
_data=$_storage/raw
workdir=$_storage/pyclone_analysis/$pbs
snpeff_config=$home/snpEff/snpEff.config
agilent=$_storage/targets/padded.clean.bed
ucsc=$_storage/targets/exons.ucsc.clean.bed
_pyclone_config=$_storage/pyclone_configs


################
# RUN ANALYSES #
################
mkdir -p $workdir/yaml/total_copy_number

## index bam samples after merging
## required for samtools and gatk workflows
cd $_data
_listingRaw=$(find . -name "*bam")

for _raw in $_listingRaw; do
    if [ ! -e $_raw.bai ]; then
	samtools index -@$threads $_raw
    fi
done

## get the total number of copy variants per sample
cd $workdir
R CMD BATCH $home/script*/r/cnv.detection.R


## run analysis one sample at a time
## the following will create one annotated pileup VCF per sample
## one VCF per sample ensures correct execution of pyClone
cd $workdir
_listingFiles=$(find $_data -name "*bam")
for _idx in $_listingFiles; do

    sample_label=$(basename $_idx | cut -f1 -d'_')
    _DIR=$(dirname $_idx)

    output[1]=output.1_bash.$pipeline.samtools.mpileup.agilent.$sample_label
    samtools mpileup -EC 50 --ignore-RG -l $agilent -f $genome_reference $_idx \
	| java -jar $varscan_dir/VarScan.jar mpileup2snp - \
	       --min-var-freq 0.01 \
	       --p-value 0.01 \
	       --output-vcf 1 \
	       > ${output[1]}.vcf


    ## get the total number of copy variants per sample
    output[2]=output.2_r.$cnvs.multi_samples.cnv
    total_cnv=$(cut -f6 ${output[2]}.txt | sed '1d' | sort - | uniq -c | awk -vc=$sample_label '{if($2 == c)print$1}')


    ## CHOICE 1
    ## annotate variants with human genome GRCh37
    ## annotate variants with dbsnp
    ## annotate variants with clinvar
    output[3]=output.3_bash.snpeff_annot.$snpeff_genome.clinvar.dbsnp.$sample_label
    java -jar $snpeff_dir/SnpSift.jar annotate \
	 -a -d -v -noLog -noDownload \
	 -c $snpeff_config \
	 -clinvar \
	 ${output[1]}.vcf \
	| java -jar $snpeff_dir/SnpSift.jar annotate \
	       -a -d -v -noLog -noDownload \
	       -c $snpeff_config \
	       -dbsnp - \
	| java -jar $snpeff_dir/snpEff.jar eff \
	       -noDownload -d -v -noLog \
	       -c $snpeff_config \
	       -stats ${output[3]}.html \
	       $snpeff_genome \
	       > ${output[3]}.vcf



    output[4]=output.4_bash.mining.snpeff_annot.$snpeff_genome.clinvar.dbsnp.$sample_label
    ## create personalized input for pyclone without annoated VCF
    grep -v "#" ${output[1]}.vcf \
	| cut -f1-2,4-5,10 \
	| sed 's/:/\t/g' \
	| awk -F"\t" '{print$1":"$2,$9,$10}' \
	| sed -e 's/ /\t/g' -e "s/$/\\t$normal_cnv\\t$minor_cnv\\t$total_cnv/g" \
	      > ${output[4]}.tsv
    sed -i "1i$(echo -e "mutation_id\tref_counts\tvar_counts\tnormal_cn\tminor_cn\tmajor_cn")" ${output[4]}.tsv


    ## CHOICE 2
    ## annotate only with dbSnp
    output[5]=output.5_bash.snpeff_annot.dbsnp.$sample_label
    java -jar $snpeff_dir/SnpSift.jar annotate \
	 -a -d -v -noLog -noDownload \
	 -c $snpeff_config \
	 -dbsnp \
	 ${output[1]}.vcf \
	 > ${output[5]}.vcf


    output[6]=output.6_bash.snpeff_annot.dbsnp.clean.$sample_label
    output[7]=output.7_bash.snpeff_annot.dbsnp.clean_pyclone.$sample_label
    ## create personalized input for pyclone from annotated VCF
    ## remove variants without annotations
    ## clean rows from mis indexed variants
    grep -v "#" ${output[5]}.vcf \
	| sed -e 's/;/\t/g' -e 's/ /\t/g' \
	| cut -f1-5,18,22,62 \
	| sed -e 's/GENEINFO.//g' -e 's/|.*\t/\t/g' -e 's/:/\t/g' \
	| tee ${output[6]}.txt \
	| awk -F"\t" '{print$7"_"$1":"$2,$13,$14}' \
	| sed -e 's/ /\t/g' -e "s/$/\t$normal_cnv\t$minor_cnv\t$total_cnv/g" \
	| grep -v "%" \
	| grep -v "^\." \
	| grep -wv "FREQ" - \
	        > ${output[7]}.tsv
    sed -i "1i$(echo -e "mutation_id\tref_counts\tvar_counts\tnormal_cn\tminor_cn\tmajor_cn")" ${output[7]}.tsv

done



## preprocess VCF for assessement of clonal evolution
## main tool: pyclone
cd $workdir

## create config files, manually
## only samples from same individual are compared together
_yaml=$(find $_pyclone_config -name "*individual*yaml")

## change the directory of each config file
## for each analysis using same samples but different iteration
for _pyCfg in $_yaml; do
    new_name=$(basename $_pyCfg)

    cat $_pyCfg \
	| sed '2d' \
	      > $workdir/$new_name
    sed -i "1i$(echo "working_dir: $workdir")" $workdir/$new_name
        
done


## run python 2.7
## load pyclone 0.13.1 that I deployed
## do not load h4h pyclone (not correctly installed)
source activate pyclone

_listingFiles=$(find $_data -name "*bam")
for _idx in $_listingFiles; do

    sample_label=$(basename $_idx | cut -f1 -d'_')

    output[7]=output.7_bash.snpeff_annot.dbsnp.clean_pyclone.$sample_label
    ## build mutation file
    PyClone build_mutations_file \
	    --in_file ${output[7]}.tsv \
	    --out_file $workdir/yaml/total_copy_number/$sample_label.yaml \
	    --prior total_copy_number

done


## run final clonal evolution analysis
## MCMC 10,000 iterations
_configFiles=$(find $workdir -name "*yaml")
for _cfg in $_configFiles; do

    _ix=$(basename $_cfg | sed -e 's/config.//g' -e 's/.yaml//g')
    
    ## build configuration file (manually)
    PyClone run_analysis --config_file $_cfg

    ## summary table
    PyClone build_table --config_file $_cfg \
	    --out_file pyclone.$_ix.exome.summary_table.txt \
	    --table_type loci

    ## plot
    PyClone plot_loci --config_file $_cfg \
	    --plot_file pyclone.$_ix.parallel.png \
	    --plot_type parallel_coordinates
    PyClone plot_loci --config_file $_cfg \
	    --plot_file pyclone.$_ix.similarity_matrix.png \
	    --plot_type similarity_matrix
    PyClone plot_loci --config_file $_cfg \
	    --plot_file pyclone.$_ix.density.png \
	    --plot_type density
done

source deactivate


## repo organization
sleep 300
cd $workdir
mkdir configs figures tsv reports vcf
mv conf*yaml configs
mv *pdf *png figures
mv *tsv tsv
mv *vcf vcf
mv *txt *html reports




end=$(date); echo "Job ended at: $end" >> $time/$jobid.time


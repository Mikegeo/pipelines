#!/bin/bash
#PBS -l nodes=1:ppn=32,walltime=168:00:00,vmem=60g,mem=220g
#PBS -N variantCalls
#PBS -q himem
#PBS -V
#PBS -j oe
#PBS -m abe
#PBS -M slei.bass@gmail.com

:'
	This batch script accomplishes 6 separate tasks
	- task 1: index merged bam files
	- task 2: call copy number variants single samples at a time
	- task 3: call, categorize, filter clean point mutations
	- task 4: annotate mutations
	- task 5: data mining (VCF formatting, thresholding, feature wrangling)
	- task 6: clonal evolution from same individual dual exome samples
'

set -eux

module load java/8 samtools/1.9 bedtools/2.27.1
module load HTSeq/0.7.2 bwa/0.7.15 bedops/2.4.14 picard/2.10.9 
module load bamtools/2.4.2 tabix/0.2.6 varscan/2.4.2 
module load snpEff/4.3
module load R/3.5.0 python/2.7 
#module load python3/3.6.5 CNVkit/0.9.3 gatk/4.0.5.1 

## use the below exec when loading R
## java -jar $gatk_dir/gatk-package-4.0.5.1-local.jar HaplotypeCaller


## H4H directories
## Misc tools parameters
scratch=/cluster/projects/kridelgroup
_storage=$scratch/relapse/mutations
home=/cluster/home/sbassim
user_databases=$scratch/databases
admin_databases=/cluster/tools/data/genomes/human/hg19/variantcallingdata
pbs=$(echo $PBS_JOBID | cut -f1 -d '.')
time=$home/time
jobid=$pbs.exome_calling.multitool.annotated_pyclone
start=$(date); echo "Job started at: $start" > $time/$jobid.time

# __CHANGE__
pipeline=bcftools
cnvs=cnmops
_protocol=removeFunctionV3
normal_cnv=2
minor_cnv=0
_priors=major_copy_number
_read_depth=50
_allel_pval=10e-25
_allel_freq=1

# __DONT CHANGE__
compression=0
threads=32
mapq=39
snpeff_genome=GRCh37.75
_data=$_storage/raw
workdir=$_storage/pyclone_analysis/$pbs
snpeff_config=$home/snpEff/snpEff.config
agilent=$_storage/targets/padded.clean.bed
ucsc=$_storage/targets/exons.ucsc.clean.bed
_pyclone_config=$_storage/pyclone_configs
## idx created from ClinVar annotating current samples
_variant_function=$_storage/variant_function.idx
_EXAC=$user_databases/gnomad.rs_position.idx
_COSMIC=$user_databases/cosmic/CosmicCodingMuts.vcf.gz
_COSMIC_mut=$user_databases/cosmic/CosmicMutantExportCensus.tsv.gz
genome_reference=$user_databases/GRCh37-lite.fa


mkdir -p $workdir/yaml/$_priors

#############################################
# Indexing and calling copy number variants #
# Batch sample CNV calling		    #
#############################################
## index bam samples after merging
## required for samtools and gatk workflows
cd $_data
_listingRaw=$(find . -name "*bam")

for _raw in $_listingRaw; do
    if [ ! -e $_raw.bai ]; then
	samtools index -@$threads $_raw
    fi
done

## get the total number of copy variants per sample
cd $workdir

if [ $cnvs == "cnvkit" ]; then
    cnvkit.py batch *.bam -n \
	      -t $agilent \
	      -f $genome_reference \
	      --short-names \
	      --output-reference $workdir/cnvkit.index_reference.cnn \
	      --annotate $ucsc \
	      -d $workdir/output.2_bash.$cnvs.multi_samples.cnv.txt

elif [ $cnvs == "cnmops" ]; then
    R CMD BATCH $home/script*/r/cnv.detection.R

else
    echo "Copy number calling approach not specified!"
    exit 0
fi



##############################################
# Single polymorphism on individual samples  #
# No batch sampling (because pyclone)	     #
# Mutation annotation with ClinVar and dbSnp #
##############################################
## run analysis one sample at a time
## the following will create one annotated pileup VCF per sample
## one VCF per sample ensures correct execution of pyClone
cd $workdir
_listingFiles=$(find $_data -name "*bam")
for _idx in $_listingFiles; do

    sample_label=$(basename $_idx | cut -f1 -d'_')
    _DIR=$(dirname $_idx)

    output[1]=output.1_bash.$pipeline.samtools.mpileup.agilent.$sample_label

    if [ $pipeline == "varscan" ]; then
	module load samtools/1.3.1
    samtools mpileup -EC 50 --ignore-RG -l $agilent -f $genome_reference $_idx \
	| java -jar $varscan_dir/VarScan.jar mpileup2snp - \
	       --min-var-freq 0.01 \
	       --p-value 0.01 \
	       --output-vcf 1 \
	       > ${output[1]}.vcf

    gzip ${output[1]}.vcf

    elif [ $pipeline == "bcftools" ]; then
	## call snps with bcftools
	module load samtools/1.9

	## generate multi-way pileup genotype likelihoods
	## max-depth is in effect when the -d 8000 default is passed
	## multiple samples can be used, pyclone requires one at a time
	## bcftools mpileup can be piped for calls for all samples
	## call snps using bcftools constrained alleles (not multiallelic -m)
	bamtools filter -tag XT:U -tag XM:0 -in $_idx \
	    | samtools view -uq39 -b - -@$threads \
	    | bcftools mpileup -Ou -EC 50 -d 1000 \
		       --targets-file $agilent \
		       --ignore-RG -f $genome_reference - \
	    | bcftools call -vcO z --skip-variants indels -o ${output[1]}.vcf.gz

	sleep 30

	## samtools mpileup stats
	tabix -p vcf ${output[1]}.vcf.gz
	bcftools stats -F $genome_reference -s - ${output[1]}.vcf.gz > ${output[1]}.stats.txt

    else
	echo "SNP calling approach not specified!"
	exit 0
    fi


    ## get the total number of copy variants per sample
    output[2]=output.2_r.$cnvs.multi_samples.cnv
    total_cnv=$(cut -f6 ${output[2]}.txt | sed '1d' | sort - | uniq -c | awk -vc=$sample_label '{if($2 == c)print$1}')
    total_cnv=2

    ## CHOICE 1
    ## annotate variants with human genome GRCh37
    ## annotate variants with dbsnp
    ## annotate variants with clinvar
    ## optional parameters -a -v -d
    output[3]=output.3_bash.snpeff_annot.$snpeff_genome.clinvar.dbsnp.$sample_label
    java -jar $snpeff_dir/SnpSift.jar annotate \
	 -noLog -noDownload \
	 -c $snpeff_config \
	 -clinvar \
	 ${output[1]}.vcf.gz \
	| java -jar $snpeff_dir/SnpSift.jar annotate \
	       -noLog -noDownload \
	       -c $snpeff_config \
	       -dbsnp - \
	| java -jar $snpeff_dir/snpEff.jar eff \
	       -noDownload -noLog \
	       -c $snpeff_config \
	       -stats ${output[3]}.html \
	       $snpeff_genome \
	       > ${output[3]}.vcf



    output[4]=output.4_bash.mining.snpeff_annot.$snpeff_genome.clinvar.dbsnp.$sample_label
    ## create personalized input for pyclone without annoated VCF
    grep -v "^#" ${output[1]}.vcf.gz \
	| cut -f1-2,4-5,10 \
	| sed 's/:/\t/g' \
	| awk -F"\t" '{print$1":"$2,$9,$10}' \
	| sed -e 's/ /\t/g' -e "s/$/\\t$normal_cnv\\t$minor_cnv\\t$total_cnv/g" \
	      > ${output[4]}.tsv
    sed -i "1i$(echo -e "mutation_id\tref_counts\tvar_counts\tnormal_cn\tminor_cn\tmajor_cn")" ${output[4]}.tsv


    ## CHOICE 2
    ## annotate only with dbSnp
    output[5]=output.5_bash.snpeff_annot.dbsnp.$sample_label
    java -jar $snpeff_dir/SnpSift.jar annotate \
	 -noLog -noDownload \
	 -c $snpeff_config \
	 -dbsnp \
	 ${output[1]}.vcf.gz \
	 > ${output[5]}.vcf



    output[6]=output.6_bash.snpeff_annot.$_protocol.noFilter_clean.$sample_label
    output[7]=output.7_bash.snpeff_annot.$_protocol.reduced.clean_pyclone.$sample_label
    ## create personalized input for pyclone from annotated VCF
    ## get annotated (rs*) mutations (MU)
    ## clean based on annotated MU (dbsnp)
    ## clean double annotated MU (rs;rs)
    ## clean based on ADP (avg depth coverage phred >= 15)
    ## clean based on allele frequency
    ## clean based on allele p-value
    ## format table to include depth -i to reference and ii- to variant
    ## clean rows with false MU index

    if [ $pipeline == "varscan" ]; then

	if [ $_protocol == "keepAnnotated" ]; then

	    ## based on dbSnp annotation formatting
	    ## this will keep gene names and rs ID
	    grep -v "^#" ${output[5]}.vcf \
		| awk 'match($3, /rs.*/) {print $0}' \
		| sed -e 's/WT=.*GENEINFO=//g' -e 's/:.*ADR\t/\t/g' -e 's/PASS.*ADP=//g' \
		| grep -v "=" \
		| sed -e 's/\trs.*;rs/\trs/g' -e 's/:/\t/g' -e 's/;/\t/g' -e 's/%//g' \
		| tee ${output[6]}.txt \
		| awk -vd=$_read_depth '{if($7 >= d) print $0}' \
		| awk -vp=$_allel_pval '{if($16 <= p) print $0}' \
		| awk -va=$_allel_freq '{if($15 <= a) print $0}' \
		| awk -F"\t" '{print$8"_"$1":"$2,$13,$14}' \
		| sed -e 's/ /\t/g' -e "s/$/\t$normal_cnv\t$minor_cnv\t$total_cnv/g" \
		| grep -v "^\." \
		| grep -wv "FREQ" - \
		       > ${output[7]}.tsv

	elif [ $_protocol == "removeAnnotated" ]; then

	    ## based on dbSnp annotation formatting
	    ## this wont keep gene names
	    grep -v "^#" ${output[5]}.vcf \
		| grep -v "rs" \
		| cut -f1-5,10 \
		| sed -e 's/:/\t/g' -e 's/%//g' \
		| tee ${output[6]}.txt \
		| awk -vp=$_allel_pval '{if($13 <= p) print $0}' \
		| awk -va=$_allel_freq '{if($12 >= a) print $0}' \
		| awk -F"\t" '{print$1":"$2,$10,$11}' \
		| sed -e 's/ /\t/g' -e "s/$/\t$normal_cnv\t$minor_cnv\t$total_cnv/g" \
		| grep -v "^\." \
		| grep -wv "FREQ" - \
		       > ${output[7]}.tsv

	elif [ $_protocol == "keepClinvar" ]; then
	    
	    ## output formatting based on clinvar and dbSnp annotation
	    ## this will keep gene handles
	    grep -v "^#" ${output[3]}.vcf \
		| grep -v "rs" \
		| sed -e 's/;WT=.*ANN=.|/\t/g' -e 's/|ENS.*:ADR//g' \
		| cut -f1-2,4-5,8-10 \
		| sed -e 's/ADP=//g' -e 's/|/\t/g' -e 's/:/\t/g' -e 's/%//g' \
		| tee ${output[6]}.txt \
		| awk -vd=$_read_depth '{if($5 >= d) print $0}' \
		| awk -vp=$_allel_pval '{if($16 <= p) print $0}' \
		| awk -va=$_allel_freq '{if($15 >= a) print $0}' \
		| awk -F"\t" '{print$8"_"$1":"$2,$13,$14}' \
		| sed -e 's/ /\t/g' -e "s/$/\t$normal_cnv\t$minor_cnv\t$total_cnv/g" \
		| grep -v "^\." \
		| grep -wv "FREQ" - \
		       > ${output[7]}.tsv


	elif [ $_protocol == "removeFunctionV1" ]; then
	    
	    ## output formatting based on clinvar and dbSnp annotation
	    ## this will keep gene handles
	    ## this will discard variants based on their functions (stop ..)
	    ## uses allele pvalue to select high confidence variants
	    grep -v "^#" ${output[3]}.vcf \
		| grep -v "rs" \
		| grep -iv "^[a-z]" \
		| sed -e 's/;WT=.*ANN=.|/\t/g' -e 's/|ENS.*:ADR//g' \
		| cut -f1-2,4-5,8-10 \
		| sed -e 's/ADP=//g' -e 's/|/\t/g' -e 's/:/\t/g' -e 's/%//g' \
		| tee ${output[6]}.txt \
		| grep -vFwf <(cat $_variant_function) - \
		| awk -vp=$_allel_pval '{if($16 <= p) print $0}' \
		| awk -F"\t" '{print$8"_"$1":"$2,$13,$14}' \
		| sed -e 's/ /\t/g' -e "s/$/\t$normal_cnv\t$minor_cnv\t$total_cnv/g" \
		| grep -v "^\." \
		| grep -wv "FREQ" - \
		       > ${output[7]}.tsv

	elif [ $_protocol == "removeFunctionV2" ]; then
	    
	    ## output formatting based on clinvar and dbSnp annotation
	    ## this will keep gene handles
	    ## this will discard variants based on their functions (stop ..)
	    ## uses variant depth, allele freq, and variant/reference ratio to discard SNVs
	    grep -v "^#" ${output[3]}.vcf \
		| grep -v "rs" \
		| grep -iv "^[a-z]" \
		| sed -e 's/;WT=.*ANN=.|/\t/g' -e 's/|ENS.*:ADR//g' \
		| cut -f1-2,4-5,8-10 \
		| sed -e 's/ADP=//g' -e 's/|/\t/g' -e 's/:/\t/g' -e 's/%//g' \
		| tee ${output[6]}.txt \
		| grep -vFwf <(cat $_variant_function) - \
		| awk -vd=$_read_depth '{if($5 >= d) print $0}' \
		| awk -vp=$_allel_pval '{if($16 <= p) print $0}' \
		| awk -F"\t" '{print$8"_"$1":"$2,$13,$14}' \
		| awk '{if($2 > $3) print $0}' \
		| sed -e 's/ /\t/g' -e "s/$/\t$normal_cnv\t$minor_cnv\t$total_cnv/g" \
		| grep -v "^\." \
		| grep -wv "FREQ" - \
		       > ${output[7]}.tsv

	elif [ $_protocol == "removeFunctionV3" ]; then
	    
	    ## output formatting based on clinvar and dbSnp annotation
	    ## this will keep gene handles
	    ## this will discard variants based on their functions (stop ..)
	    ## uses variant depth, allele freq, and pvalues
	    ## this will discard variants also found in exAC
	    grep -v "^#" ${output[3]}.vcf \
		| grep -v "rs" \
		| grep -iv "^[a-z]" \
		| sed -e 's/;WT=.*ANN=.|/\t/g' -e 's/|ENS.*:ADR//g' \
		| cut -f1-2,4-5,8-10 \
		| sed -e 's/ADP=//g' -e 's/|/\t/g' -e 's/:/\t/g' -e 's/%//g' \
		| grep -vFwf <(cat $_EXAC) \
		| grep -vFwf <(zcat $_COSMIC | cut -f2 | sed '1d') - \
		| grep -vFwf <(zcat $_COSMIC_mut | grep -o ":.*-" | sed -e 's/://g' -e 's/-.*$//g') \
		| tee ${output[6]}.txt \
		| grep -vFwf <(cat $_variant_function) - \
		| egrep -iv "^\.|muc|usp|rp11" \
		| awk -F"\t" '{print$8"_"$1":"$2,$13,$14}' \
		| sed -e 's/ /\t/g' -e "s/$/\t$normal_cnv\t$minor_cnv\t$total_cnv/g" \
		       > ${output[7]}.tsv

	else


	    echo "Must specify whether to remove or keep annotated known SNVs!"
	    exit 0

	fi
	
    elif [ $pipeline == "bcftools" ]; then

	## output formatting based on clinvar and dbSnp annotation
	## this will keep gene handles
	## this will discard variants based on their functions (stop ..)
	## this will discard variants also found in exAC
	grep -v "^#" ${output[3]}.vcf \
	    | grep -v "rs" \
	    | grep -iv "^[a-z]" \
	    | sed -e 's/;WT=.*ANN=.|/\t/g' -e 's/|ENS.*:ADR//g' \
	    | cut -f1-2,4-5,8-10 \
	    | sed -e 's/ADP=//g' -e 's/|/\t/g' -e 's/:/\t/g' -e 's/%//g' \
	    | grep -vFwf <(cat $_EXAC) \
	    | tee ${output[6]}.txt \
	    | grep -vFwf <(cat $_variant_function) - \
	    | egrep -iv "^\.|muc|usp|rp11" \
	    | awk -F"\t" '{print$8"_"$1":"$2,$13,$14}' \
	    | sed -e 's/ /\t/g' -e "s/$/\t$normal_cnv\t$minor_cnv\t$total_cnv/g" \
		   > ${output[7]}.tsv


    else
	echo "VCF data reformatting for pattern recognition procedures not specified!"
	exit 0
    fi

    sed -i "1i$(echo -e "mutation_id\tref_counts\tvar_counts\tnormal_cn\tminor_cn\tmajor_cn")" ${output[7]}.tsv


    ## summary reporting
    ## descriptive statistics
    ## distribution of variant by function
    output[8]=output.8_bash.summary.snv_functions.txt
    grep -v "^#" ${output[6]}.txt \
	| cut -f6 \
	| sort - \
	| uniq -c \
	| awk '{print $2,"\t",$1}' \
	| sed "s/$/\t$sample_label/g" \
	      >> ${output[8]}

    ## pvalues and variant frequencies (VAF) by all SNV position
    output[9]=output.9_bash.summary.snv.preFilter_distributions.txt
    grep -v "^#" ${output[6]}.txt \
	| awk -F"\t" '{print$8"_"$1":"$2,$5,$13,$14,$15,$16}' \
	| sed "s/$/\t$sample_label/g" \
	      >> ${output[9]}


    ## pvalues and variant allele frequencies (VAF) by SNV position
    ## after discarding based on filters
    output[10]=output.10_bash.summary.snv.postFilter_VAFpval.txt
    grep -v "^#" ${output[6]}.txt \
	| grep -vFwf <(cat $_variant_function) - \
	| egrep -iv "^\.|muc|usp|rp11" \
	| awk -F"\t" '{print$8"_"$1":"$2,$5,$13,$14,$15,$16}' \
	| sed "s/$/\t$sample_label/g" \
	      >> ${output[10]}



done

## add headers for summary reports
sed -i "1i $(echo -e "function\tcount\tsample")" ${output[8]}
sed -i "1i $(echo -e "function\tcount\tsample")" ${output[9]}
sed -i "1i $(echo -e "snv\tDP\trefCounts\tvarCounts\tvaf\tpval\tsample")" ${output[10]}



##############################################
# Clonal evolution by pair samples (pyClone) #
##############################################
## preprocess VCF for assessement of clonal evolution
## main tool: pyclone
cd $workdir

## create config files, manually
## only samples from same individual are compared together
_yaml=$(find $_pyclone_config -name "*individual*yaml")

## change the directory of each config file
## for each analysis using same samples but different iteration
for _pyCfg in $_yaml; do
    new_name=$(basename $_pyCfg)

    cat $_pyCfg \
	| sed '2d' \
	      > $workdir/$new_name
    sed -i "1i$(echo "working_dir: $workdir")" $workdir/$new_name
        
done


## run python 2.7
## load pyclone 0.13.1 that I deployed
## do not load h4h pyclone (not correctly installed)
source activate pyclone

_listingFiles=$(find $_data -name "*bam")
for _idx in $_listingFiles; do

    sample_label=$(basename $_idx | cut -f1 -d'_')

    output[7]=output.7_bash.snpeff_annot.$_protocol.reduced.clean_pyclone.$sample_label
    ## build mutation file
    PyClone build_mutations_file \
	    --in_file ${output[7]}.tsv \
	    --out_file $workdir/yaml/total_copy_number/$sample_label.yaml \
	    --prior $_priors

done


## run final clonal evolution analysis
## MCMC 10,000 iterations
_configFiles=$(find $workdir -name "config*yaml")
for _cfg in $_configFiles; do

    _ix=$(basename $_cfg | sed -e 's/config.//g' -e 's/.yaml//g')
    
    ## build configuration file (manually)
    PyClone run_analysis --config_file $_cfg

    ## summary table
    PyClone build_table --config_file $_cfg \
	    --out_file pyclone.$_ix.exome.summary_table.txt \
	    --table_type loci

    ## plot
    PyClone plot_loci --config_file $_cfg \
	    --plot_file pyclone.$_ix.parallel.png \
	    --plot_type parallel_coordinates
    PyClone plot_loci --config_file $_cfg \
	    --plot_file pyclone.$_ix.similarity_matrix.png \
	    --plot_type similarity_matrix
    PyClone plot_loci --config_file $_cfg \
	    --plot_file pyclone.$_ix.density.png \
	    --plot_type density
done

source deactivate


## repo organization
sleep 300
cd $workdir
mkdir configs figures pyclone_input reports variants
mv *tsv pyclone_input
mv *gz variants
mv conf*yaml configs
mv *txt reports
mv *pdf *png *html figures




end=$(date); echo "Job ended at: $end" >> $time/$jobid.time
